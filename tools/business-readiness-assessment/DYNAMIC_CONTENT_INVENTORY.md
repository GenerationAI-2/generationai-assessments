# Business AI Readiness Assessment - Dynamic Content Inventory

**Version 2.0 | Updated: 2025-11-07**

This document lists all dynamic text content that appears in the assessment report based on user responses. All content uses NZ English spelling with no em dashes.

---

## 1. SCORE & MATURITY BANDS

### Score Display
- **Format**: `X/100` (0-100 scale)
- **Calculated from**: Total of 10 questions (0-5 points each, total 0-50, converted to 0-100)

### Maturity Bands & Narratives

**Band: Blind (0-25)**
> You have zero visibility on AI — you're either missing opportunities or exposed to risks you can't see.

**Band: Reactive (26-50)**
> AI is likely happening in the shadows while you have no plan. You can't manage what you can't see.

**Band: Building (51-75)**
> You've got awareness, but execution is fragile without a clear roadmap and consistent governance.

**Band: Ready (76-100)**
> You've got strong foundations. The question now is execution speed and sustaining momentum.

---

## 2. TENSION LINES (Uncomfortable Truth)

**4-Tier Logic (Matching Maturity Bands):**

**Score ≤25:**
> You have zero visibility on AI — you're either missing opportunities or exposed to risks you can't see.

**Score 26-50:**
> AI is likely happening in the shadows while you have no plan. You can't manage what you can't see.

**Score 51-75:**
> You've got awareness, but execution is fragile without a clear roadmap and consistent governance.

**Score 76-100:**
> You've got strong foundations. The question now is execution speed and sustaining momentum.

---

## 3. AI READINESS PLAYBOOK (5-Step Framework)

### Heading
> The AI Readiness Playbook

### Intro Line
> From our work with dozens of New Zealand businesses, successful AI adoption always follows this pattern:

### Five Steps (Static)

**Step 1: Leadership Readiness**
> Upskill your leaders first, they can't lead AI if they don't understand it. AI is not an IT project. It needs to be led from the top with clear messaging that builds trust.

**Step 2: Discovery & Transparency**
> Find out what's happening. Talk to your people. Uncover Shadow AI before it becomes a problem. You can't manage what you can't see.

**Step 3: Guardrails & Governance**
> Put basic policies in place that enable safe use. Treat AI like health and safety: practical controls, not prohibition. Define what's safe and what's not.

**Step 4: Capability Building**
> Identify champions. Build skills across your people so they can use AI safely and effectively.

**Step 5: Strategy & Execution**
> Start with small pilots that solve real problems and deliver ROI. Build the foundation before you scale. Develop a digital strategy that aligns AI to business goals and customer value.

---

---

## 4. QUESTION-BY-QUESTION FEEDBACK

### Q1: Leadership & Ownership

**Option 5 (Best):**
- **Playback**: You told us AI ownership sits clearly at executive level and is actively driving decisions.
- **Interpretation**: This is best-practice leadership. Ownership is visible, strategic, and aligned to business outcomes. AI is treated as a capability, not a tech project. You're positioned to scale safely and confidently.

**Option 4:**
- **Playback**: You said a senior leader owns AI, but it's not widely visible across the organisation.
- **Interpretation**: You have an owner, but they're not empowered. Without budget, mandate, or visible CEO backing, ownership becomes a side project. The role needs real authority. Otherwise this is leadership theatre, not leadership action.

**Option 3:**
- **Playback**: You told us AI has shared interest across leaders but no single person owns it.
- **Interpretation**: Shared interest without ownership means endless discussion but no decisions. Everyone agrees AI matters, but nobody drives it forward. Without a single accountable owner, AI remains trapped in committee. Assign one leader with clear authority, budget, and mandate.

**Option 2:**
- **Playback**: You said AI has been discussed by leadership, but no one owns it yet.
- **Interpretation**: Leadership is aware, but paralysed. Everyone agrees someone should own it, but nobody wants the responsibility. Meanwhile, Shadow AI spreads and competitors advance. This indecision costs more than any wrong decision would.

**Option 1:**
- **Playback**: You told us no one owns AI, and there's no plan to change that.
- **Interpretation**: This is passive exposure. AI will still be adopted, just without guidance. Every week without ownership means deeper fragmentation. Assign an owner within days, not months.

**Option 0 (Worst):**
- **Playback**: You said you don't know whether AI ownership exists or has even been discussed.
- **Interpretation**: AI is happening without any leadership oversight. No one is watching the risks, shaping the opportunities, or guiding adoption. This is an organisational blindspot, and a strategic liability.

---

### Q2: AI in Strategic Planning

**Option 5:**
- **Playback**: You told us AI is embedded in your strategic plans and actively reviewed at leadership level.
- **Interpretation**: AI is treated as a strategic capability, not a side project. This integration means AI investments align with business outcomes, not technology experiments. You're positioned to capture value systematically rather than opportunistically.

**Option 4:**
- **Playback**: You said AI is regularly discussed at board or executive level meetings.
- **Interpretation**: Leadership engagement is strong, but discussion without documentation risks drift. Until AI moves from agenda item to strategic plan, execution remains informal. Document the strategy to convert conversation into coordinated action.

**Option 3:**
- **Playback**: You told us AI appears in planning documents but hasn't translated to action.
- **Interpretation**: This is strategic theatre, AI is mentioned to appear current, but without execution it's just words on paper. The gap between documentation and action is where competitive advantage is lost. Move from planning to pilots immediately.

**Option 2:**
- **Playback**: You said AI is mentioned informally by leaders but isn't part of formal planning.
- **Interpretation**: AI is a talking point, not a strategic priority. Informal mentions create confusion, staff don't know if it's encouraged or just discussed. Without formal inclusion in strategy, AI adoption will remain scattered and ineffective.

**Option 1:**
- **Playback**: You told us AI isn't included in any business planning activities.
- **Interpretation**: Your strategy is silent on the biggest business transformation of our time. While you plan without AI, competitors are planning with it. This absence isn't neutral, it's an active decision to fall behind.

**Option 0:**
- **Playback**: You said AI hasn't been discussed or considered at strategic level.
- **Interpretation**: AI is completely off your radar while reshaping every industry. This isn't just oversight, it's strategic blindness. Begin with a leadership briefing on what AI means for your sector, otherwise you're planning for yesterday's market.

---

### Q3: Cultural Readiness

**Option 5:**
- **Playback**: You told us staff are actively encouraged, supported, and confident in using AI tools.
- **Interpretation**: You've created psychological safety around AI experimentation. This cultural foundation is harder to build than any technical capability. Staff feel empowered to explore, fail, and improve. This is where sustainable transformation happens.

**Option 4:**
- **Playback**: You said most staff are positive about AI, with champions starting to emerge across teams.
- **Interpretation**: Momentum is building organically. Champions are your multiplier effect, they'll influence peers more effectively than any top-down mandate. Support these early adopters visibly to accelerate cultural shift across the organisation.

**Option 3:**
- **Playback**: You told us there are mixed responses, with pockets of resistance and uncertainty.
- **Interpretation**: This is typical and manageable. The split usually follows generational or role lines. Resistance often masks fear, fear of replacement, irrelevance, or failure. Address the fear directly with clear messaging about augmentation, not automation.

**Option 2:**
- **Playback**: You said there's limited engagement, with little visible experimentation happening.
- **Interpretation**: Staff are watching and waiting. This passive stance usually means either no permission, no tools, or no confidence. Without cultural momentum, even good tools and policies will fail. Start with visible, low-risk use cases that make daily work easier.

**Option 1:**
- **Playback**: You told us there's clear hesitation or active pushback from staff regarding AI.
- **Interpretation**: You're facing cultural headwinds. Pushback signals deeper issues, lack of trust, fear of job losses, or past failed initiatives. This resistance will sabotage any AI initiative unless addressed. Start with listening sessions, not technology rollouts.

**Option 0:**
- **Playback**: You said there's no visible engagement or cultural signals around AI adoption.
- **Interpretation**: Staff are either unaware or indifferent. Without curiosity or engagement, transformation won't happen. Start with education and safe experimentation before imposing policies.

---

### Q4: Staff Enablement & Training

**Option 5:**
- **Playback**: You told us staff have received role-specific training with structured enablement for their AI use.
- **Interpretation**: You're building capability systematically. Role-specific training means staff learn what's relevant, not generic. This targeted approach accelerates adoption and reduces risk. The investment in structured enablement will compound as staff become multipliers of capability.

**Option 4:**
- **Playback**: You said formal training sessions or resources have been provided to most teams.
- **Interpretation**: You've made a solid start, but coverage gaps remain. "Most teams" means some teams are operating without guidance, often those who need it most. Complete the rollout before unguided teams create risks or fall behind.

**Option 3:**
- **Playback**: You told us basic guidance has been shared with staff across the organisation.
- **Interpretation**: Guidance without training means staff know the rules but not the tools. This creates hesitation and low adoption. People won't use tools they don't understand. Follow guidance with hands-on enablement.

**Option 2:**
- **Playback**: You said staff have been told they can use AI, but no training or resources have been provided.
- **Interpretation**: Permission without enablement leads to chaos. Staff experiment blindly, creating inconsistent quality and hidden risk. This is how data breaches happen, through good intentions and poor knowledge. Provide training immediately.

**Option 1:**
- **Playback**: You told us staff are expected to figure it out themselves, with no formal support.
- **Interpretation**: This is wishful thinking at scale. A few tech-savvy staff will thrive; most will flounder or opt out. Capability gaps will widen, and organisational value will concentrate in the hands of a few. Enablement is not optional for strategic adoption.

**Option 0:**
- **Playback**: You said no training, guidance, or resources have been provided to staff at all.
- **Interpretation**: Staff are in the dark. Any AI usage is happening by accident, with maximum risk and minimal value. This is where Shadow AI thrives. Begin with basic education and approved tools.

---

### Q5: Shadow AI Exposure

**Option 5:**
- **Playback**: You told us your staff are not using unapproved AI tools, and you have controls in place to ensure that.
- **Interpretation**: You've established clear expectations, approved tools, and strong oversight. Shadow AI isn't just low, it's actively prevented. This reflects mature policy, communication, and trust.

**Option 4:**
- **Playback**: You said only minimal Shadow AI use is happening, in isolated cases.
- **Interpretation**: You have strong awareness and controls. Isolated cases are normal, perfect compliance is unrealistic. The key is rapid detection and correction. Monitor these cases to prevent spread.

**Option 3:**
- **Playback**: You told us some Shadow AI use is happening but it's limited and manageable.
- **Interpretation**: You're in the danger zone. "Manageable" often means visible but not contained. Shadow AI spreads through peer influence. What starts as a few tools becomes department-wide adoption within weeks. Act now before limited becomes systemic.

**Option 2:**
- **Playback**: You said widespread Shadow AI usage is occurring across the organisation.
- **Interpretation**: This is crisis-level exposure. Shadow AI is shaping work at scale, and leadership has no visibility. Act within days, not weeks, to assess risk and reassert control.

**Option 1:**
- **Playback**: You said you don't know whether staff are using AI tools, or to what extent.
- **Interpretation**: You can't protect what you can't see. Shadow AI is definitely active, and data is likely exposed. Start with a discovery exercise to understand your true exposure before incidents occur.

**Option 0:**
- **Playback**: You said you don't know whether staff are using AI tools, or to what extent.
- **Interpretation**: You can't protect what you can't see. Shadow AI is definitely active, and data is likely exposed. Start with a discovery exercise to understand your true exposure before incidents occur.

---

### Q6: Governance Framework

**Option 5:**
- **Playback**: You told us you have clear AI governance policies actively enforced across the organisation.
- **Interpretation**: Strong governance means you can scale safely. Clear rules, approved tools, and active enforcement create boundaries that enable innovation rather than block it. This is enterprise readiness.

**Option 4:**
- **Playback**: You said governance policies exist but enforcement is still developing.
- **Interpretation**: Policy without enforcement is just guidance. Staff will follow the path of least resistance. If Shadow AI tools are easier than approved ones, they'll use Shadow AI. Strengthen enforcement to make compliance the easy choice.

**Option 3:**
- **Playback**: You told us informal guidelines exist but no formal governance is in place.
- **Interpretation**: Informal guidelines create confusion. What's encouraged? What's forbidden? Without clarity, staff will interpret differently. Formalise governance to create consistent expectations and protection.

**Option 2:**
- **Playback**: You said staff have been told not to use AI, with no guidance or approved alternatives.
- **Interpretation**: Prohibition without provision drives behaviour underground. Staff who need productivity tools will find them anyway, just without your knowledge or control. This approach guarantees Shadow AI. The first incident will be your wake up call. Provide safe alternatives or accept hidden risk.

**Option 1:**
- **Playback**: You said there's been no discussion of AI governance or guardrails at all.
- **Interpretation**: AI governance isn't on the radar. Without visibility, policy, or ownership, you have no ability to detect, contain, or respond to incidents. The first incident (an AI hallucination in a client report, sensitive data exposure, or compliance inquiry) will force this conversation. Begin with discovery and leadership alignment.

**Option 0:**
- **Playback**: You said there's been no discussion of AI governance or guardrails at all.
- **Interpretation**: AI governance isn't on the radar. Without visibility, policy, or ownership, you have no ability to detect, contain, or respond to incidents. The first incident (an AI hallucination in a client report, sensitive data exposure, or compliance inquiry) will force this conversation. Begin with discovery and leadership alignment.

---

### Q7: Legal & Compliance Confidence

**Option 5:**
- **Playback**: You told us you're fully confident, with legal obligations mapped and controls actively enforced.
- **Interpretation**: You've done the work others avoid. Mapping obligations to controls means compliance by design, not luck. This positions you to respond confidently to regulators, auditors, or clients. Maintain this through regular reviews as AI regulations evolve rapidly.

**Option 4:**
- **Playback**: You said you're mostly confident, with key risks identified and mitigation in place.
- **Interpretation**: You understand the landscape but haven't mapped every detail. "Mostly confident" often means known unknowns remain. The gap between mostly and fully confident is where incidents hide. Close those gaps before they close on you.

**Option 3:**
- **Playback**: You told us you're somewhat confident, with partial understanding of obligations.
- **Interpretation**: This uncertainty is common but dangerous. "Somewhat confident" in legal compliance is like being "somewhat pregnant", you either comply or you don't. Partial understanding leads to partial protection. Get legal clarity before an incident forces it.

**Option 2:**
- **Playback**: You said you're not confident, with limited awareness of legal obligations.
- **Interpretation**: You know enough to be worried, but not enough to be safe. This honesty is valuable, it's better than false confidence. But worry without action is just anxiety. Map your obligations urgently; ignorance isn't a legal defence.

**Option 1:**
- **Playback**: You told us you know compliance obligations aren't being met.
- **Interpretation**: Operating knowingly out of compliance is the highest-risk position. Every day increases liability. Regulators and auditors view this differently than ignorance. This needs immediate attention and legal review.

**Option 0:**
- **Playback**: You said you have no idea whether legal obligations are being met.
- **Interpretation**: Total blindness to compliance creates compounding liability. AI regulations are tightening globally. Operating without any compliance awareness is gambling with the organisation's reputation and your personal accountability.

---

### Q8: Resource Allocation

**Option 5:**
- **Playback**: You told us dedicated budget and people are allocated to AI capability building.
- **Interpretation**: Resources signal seriousness. Budget without people, or people without budget, both fail. You have both, which means execution capability. The challenge now is using resources strategically rather than reactively.

**Option 4:**
- **Playback**: You said some budget exists and informal resources are being used.
- **Interpretation**: You're in the pilot phase. Small budgets and informal resourcing work for experiments but won't scale. Define success criteria now so you can justify the step-up to strategic investment when pilots prove value.

**Option 3:**
- **Playback**: You told us resources exist but haven't been allocated to AI yet.
- **Interpretation**: Resources exist but aren't committed. This suggests AI hasn't crossed the threshold from "interesting" to "strategic priority." Until budget and people are allocated, AI will remain secondary to everything else. Make the call.

**Option 2:**
- **Playback**: You said no specific budget or people have been allocated to AI initiatives.
- **Interpretation**: Good intentions without resources means AI stays in the talking phase. Meanwhile, competitors are investing. If AI matters strategically, resource it. If not, stop pretending it does.

**Option 1:**
- **Playback**: You told us there's no discussion of resource allocation for AI.
- **Interpretation**: No resources means no execution. AI won't happen by accident. If you want strategic AI capability, fund it. Without resources, you're watching from the sidelines while others build advantage.

**Option 0:**
- **Playback**: You said there's no discussion of resource allocation for AI.
- **Interpretation**: No resources means no execution. AI won't happen by accident. If you want strategic AI capability, fund it. Without resources, you're watching from the sidelines while others build advantage.

---

### Q9: Data Protection Confidence

**Option 5:**
- **Playback**: You said you're fully confident that strong technical controls are in place to prevent data exposure through AI tools.
- **Interpretation**: This reflects a mature security posture. Approved tools, usage monitoring, and clear controls are working together to protect sensitive data. You're treating AI as a data processor, and managing the risks accordingly.

**Option 4:**
- **Playback**: You told us you're confident data is protected through a combination of policies, training, and monitoring.
- **Interpretation**: You've built solid protection, but policy without enforcement can drift. Stay proactive. Periodic audits and tighter controls on new tools will help maintain this confidence over time.

**Option 3:**
- **Playback**: You said you're somewhat confident, relying on staff judgement rather than formal controls.
- **Interpretation**: This creates inconsistency. Some staff may be cautious; others may paste sensitive info into free tools without thinking. Relying on individual judgment is not a sustainable defence. Formalise your guidance before an incident forces the issue.

**Option 2:**
- **Playback**: You told us you're not confident, and that some sensitive data has likely been exposed.
- **Interpretation**: Sensitive documents, client details, or IP may already be in free tools with no oversight or audit trail. This level of exposure presents reputational, legal, and operational risk. You'll need to act quickly to contain and correct.

**Option 1:**
- **Playback**: You said you know sensitive data has been entered into AI tools without approval.
- **Interpretation**: The breach has already happened. If left unaddressed, this erodes trust with staff, clients, and partners. Begin with a formal review of what's been shared, by whom, and what controls are missing. Visibility is the first step toward recovery.

**Option 0:**
- **Playback**: You said you don't know whether any sensitive data has been shared, or with which tools.
- **Interpretation**: You have zero visibility into data exposure. This is the highest-risk state, confirmed breaches are bad, but unknown breaches are worse. Start with discovery immediately.

---

### Q10: Opportunity Understanding

**Option 5:**
- **Playback**: You told us specific opportunities are mapped and prioritised, with business cases ready.
- **Interpretation**: You've done the strategic work. Mapped opportunities with business cases means you can move directly to execution. This clarity separates you from organisations still stuck in the "where do we start?" phase.

**Option 4:**
- **Playback**: You said several clear opportunities have been identified and are being explored.
- **Interpretation**: You know where AI can help and you're moving toward action. The risk now is analysis paralysis, too much exploration, not enough execution. Pick one high-value use case and prove it works.

**Option 3:**
- **Playback**: You told us you have a general sense of where AI might help, but no specific initiatives yet.
- **Interpretation**: You see the potential, but it's still abstract. Most businesses in this zone are missing 70 to 80% of the actual opportunity. A focused opportunity scan typically reveals far more upside than initially expected.

**Option 2:**
- **Playback**: You said there's a vague awareness that AI could help, but no clarity on where or how.
- **Interpretation**: AI is conceptual, not practical. Without specific opportunities, AI remains a solution looking for a problem. Start with pain points, where does work feel slow, manual, or repetitive? That's where AI delivers fastest.

**Option 1:**
- **Playback**: You told us no one has looked at where or how AI could benefit the organisation.
- **Interpretation**: You're operating blind to opportunity while competitors map theirs. A simple opportunity scan, 2-4 hours with key stakeholders, will reveal 10-15 use cases. Start there.

**Option 0:**
- **Playback**: You said you don't see how AI is relevant to your business.
- **Interpretation**: This is the biggest risk of all, missed opportunity. While others reduce admin, improve customer service, or speed up delivery, you're sitting out the shift. Most organisations that say this revise their view once they see real examples.

---

## 5. PRIORITY GAPS (Top 3)

### Gap Selection Logic
- **Only include questions with scores < 5** (imperfect scores)
- Select 3 lowest-scoring questions as priority gaps
- If fewer than 3 imperfect scores, show fewer gaps
- **If no imperfect scores (perfect 100/100), hide this entire section**

### Gap Titles, Descriptions & Micro-Recommendations

**Q1: No executive ownership of AI**
- **Description**: Without clear leadership accountability, AI adoption will remain fragmented and ineffective.
- **Recommendation**: Strengthen accountability: assign a clear AI owner at leadership level to drive strategy and governance.

**Q2: AI absent from strategy**
- **Description**: Strategic planning that ignores AI means missing the biggest transformation opportunity of our time.
- **Recommendation**: Bring AI into strategic planning. Make leadership responsible for aligning it with business priorities (accountability and transparency working together).

**Q3: Cultural resistance or uncertainty**
- **Description**: Without cultural buy-in, even the best tools and policies will fail to deliver value.
- **Recommendation**: Build trust: start conversations about what AI means for your team, address concerns openly, and involve people in shaping safe use.

**Q4: No staff training or enablement**
- **Description**: Untrained staff create risk through well-intentioned mistakes and missed opportunities.
- **Recommendation**: Build capability: upskill your people so they can use approved tools safely and effectively.

**Q5: Shadow AI exposure**
- **Description**: Unmanaged AI use means data exposure, compliance risk, and loss of control.
- **Recommendation**: You can't govern what you can't see. Start with transparency: run a quick Shadow AI discovery and open the conversation with your team.

**Q6: No governance framework**
- **Description**: Without clear policies and guardrails, you can't manage risk or scale safely.
- **Recommendation**: Set the foundations for trust: create basic guardrails and policies that make safe, ethical use easy.

**Q7: Legal compliance uncertainty**
- **Description**: Operating without clarity on legal obligations creates liability that compounds daily.
- **Recommendation**: Strengthen accountability: get legal and leadership aligned on compliance obligations and document your approach.

**Q8: No resources allocated**
- **Description**: Good intentions without budget and people means AI remains stuck in the talking phase.
- **Recommendation**: Show accountability and intent: allocate time, budget, and people to manage AI adoption deliberately.

**Q9: Data exposure risk**
- **Description**: Without controls, sensitive data is likely being shared with AI tools invisibly.
- **Recommendation**: Protect trust: implement basic controls to prevent sensitive data from being shared with AI tools invisibly.

**Q10: Opportunities not identified**
- **Description**: You can't capture value you haven't identified. Start by mapping where AI could help.
- **Recommendation**: Start with transparency: map where AI could add value across operations, customer experience, and decision making.

### Gap Summary Statements (by Maturity Band)

**Blind (0-25):**
> These gaps represent critical blind spots. Start with Leadership Mastery and Shadow AI discovery.

**Reactive (26-50):**
> These gaps prevent coordinated progress. Focus on establishing basic Governance & Trust to enable safe experimentation.

**Building (51-75):**
> These gaps limit your ability to scale. Address them systematically to strengthen Execution & Evolution.

**Ready (76-100):**
> These represent optimization opportunities. Focus here to maximize ROI and competitive advantage.

### Bridging Sentence (appears after gaps list)
> These recommendations map directly to the GEN5™ framework: the five essential elements every business needs to move from AI exposure to AI advantage.

---

## 6. CALL TO ACTION

### CTA Heading
> BOOK YOUR 20-MINUTE DISCOVERY CALL

### CTA Body
> On the call, we'll:

### CTA Bullets
- Review your results together and answer any questions
- Discuss the roadmap that fits your business
- Recommend your first move

### CTA Promise
> You'll walk away with a clear next action, whether you work with us or not.

### CTA Scheduler
- **Web**: HubSpot embedded scheduler with prefilled name, email, company
- **PDF**: https://meetings-ap1.hubspot.com/caleb-lucas1

### Scheduler Heading
> Pick a time that works for you

---

## 7. SUCCESS FOOTER

### Content (appears before main footer)
> Most businesses that start here see measurable improvement within 90 days: tighter governance, safer experimentation, and clearer ROI.

---

## 8. METADATA & SYSTEM TEXT

### Journey Signpost (Vertical Layout)
- **Label**: You are here
- **Path**: **Assess** → Learn → Grow → Transform

### Email Subject Line
> Your Business AI Readiness Report - [Score]/100

### Report Footer (PDF)

**Important Disclaimers:**
> This assessment is based on information provided during completion and represents a point-in-time snapshot of your organisation's Business AI Readiness profile. Results depend on the accuracy and completeness of responses provided.

> GenerationAI cannot assess risks or activities not disclosed during the diagnostic process. This diagnostic is designed to build awareness and guide strategic thinking about AI readiness and risk management.

**Copyright:**
> © 2025 GenerationAI. All rights reserved.

---

## 9. VISUAL STYLING LOGIC

### Score-Based Color Coding (Answer Playback Boxes)

**Score 5 (Excellent):**
- Background: `#D1FAE5` (Dark Green)
- Border: `2px solid #10B981`

**Score 4 (Good):**
- Background: `#ECFDF5` (Light Green)
- Border: `2px solid #6EE7B7`

**Score 3 (Moderate):**
- Background: `#FEF3C7` (Yellow/Amber)
- Border: `2px solid #FCD34D`

**Score 2 (Needs Attention):**
- Background: `#FED7AA` (Orange)
- Border: `2px solid #FB923C`

**Score 0-1 (Critical):**
- Background: `#FEE2E2` (Red)
- Border: `2px solid #EF4444`

### Recommendation Styling
- Background: `#EFF6FF` (Very Light Blue)
- Border: `3px solid var(--primary-blue)` (left border only)
- Font: Bold, Italic
- Color: `var(--primary-blue)`

---

## 10. LOGIC RULES SUMMARY

### Tension Line Selection (4-Tier - Matches Maturity Bands)
- If score ≤25 → "You have zero visibility on AI..."
- If score 26-50 → "AI is likely happening in the shadows..."
- If score 51-75 → "You've got awareness, but execution is fragile..."
- If score 76-100 → "You've got strong foundations..."

### Gap Selection & Display
- Only include questions with scores < 5
- Select 3 lowest scores as priority gaps
- **Hide entire gaps section if no imperfect scores exist**
- Add recommendation below each gap description
- Add bridging sentence after all gaps

### Phase Label (Internal - matches maturity band)
- If score ≤25 → "Blind"
- If score 26-50 → "Reactive"
- If score 51-75 → "Building"
- If score 76-100 → "Ready"

---

## 11. BRAND CONSISTENCY

### Color Palette
- **Primary Blue**: `#1E40AF`
- **Light Gray**: `#F3F4F6`
- **Very Light Blue**: `#EFF6FF`
- **Dark Navy**: `#1E293B`
- **Lime Accent**: `#84CC16`

### Typography
- Headings: Bold, Dark Navy
- Body: Regular, Dark Gray
- Emphasis: Bold or Italic (never both)

### Border & Spacing
- Border Radius: `12px` (large), `8px` (medium)
- Border: `1px solid #E5E7EB` (light gray)
- Accent borders: `2-3px solid` with color

---

*Document Version: 3.0*
*Last Updated: 2025-01-13*
*All content uses NZ English spelling*
*Major Update: Maturity bands renamed (Unmanaged→Blind, Ad Hoc→Reactive, Developing→Building), new 5-step playbook framework, GEN5™ framework integration*
